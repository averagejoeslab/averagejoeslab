<!doctype html>
<html lang="en" dir="ltr" class="plugin-pages plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">External Papers &amp; Reproductions ‚Ä¢ Average Joes Lab</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://averagejoeslab.com/img/ajlabs-logo-light.png"><meta data-rh="true" name="twitter:image" content="https://averagejoeslab.com/img/ajlabs-logo-light.png"><meta data-rh="true" property="og:url" content="https://averagejoeslab.com/external-papers"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="External Papers &amp; Reproductions ‚Ä¢ Average Joes Lab"><meta data-rh="true" name="description" content="External research papers tracked, reviewed, and reproduced by the Average Joes Lab community. Our commitment to validating existing research."><meta data-rh="true" property="og:description" content="External research papers tracked, reviewed, and reproduced by the Average Joes Lab community. Our commitment to validating existing research."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://averagejoeslab.com/external-papers"><link data-rh="true" rel="alternate" href="https://averagejoeslab.com/external-papers" hreflang="en"><link data-rh="true" rel="alternate" href="https://averagejoeslab.com/external-papers" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Average Joes Lab RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Average Joes Lab Atom Feed">




<script src="/js/blogSidebarFix.js" async></script><link rel="stylesheet" href="/assets/css/styles.f9a79fea.css">
<script src="/assets/js/runtime~main.9a31f06d.js" defer="defer"></script>
<script src="/assets/js/main.89627151.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/ajlabs-logo-light.png"><link rel="preload" as="image" href="/img/ajlabs-logo-dark.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/ajlabs-logo-light.png" alt="Average Joes Lab Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/ajlabs-logo-dark.png" alt="Average Joes Lab Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Average Joes Lab</b></a><a class="navbar__item navbar__link" href="/docs/research-engineering/getting-started">Learning Path</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Research</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/internal-papers">Internal Papers</a></li><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/external-papers">External Papers</a></li></ul></div><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://discord.gg/7gzZMAPuGr" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Discord<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><a href="https://github.com/averagejoeslab" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><header class="hero papersHero_tts6"><div class="container"><div class="row"><div class="col col--8 col--offset-2"><div class="text--center"><h1 class="hero-title">External Papers &amp; Reproductions</h1><p class="hero-subtitle">Tracking, reviewing, and reproducing important research papers from the broader scientific community. Our commitment to validating and building upon existing research.</p></div></div></div></div></header><main><section class="section-stats"><div class="container"><div class="row"><div class="col col--3"><div class="stat-card"><div class="stat-icon">üìÑ</div><div class="stat-value">7</div><div class="stat-label">Total Papers</div></div></div><div class="col col--3"><div class="stat-card"><div class="stat-icon">üîç</div><div class="stat-value">5</div><div class="stat-label">Triaged</div></div></div><div class="col col--3"><div class="stat-card"><div class="stat-icon">üî¨</div><div class="stat-value">2</div><div class="stat-label">In Progress</div></div></div><div class="col col--3"><div class="stat-card"><div class="stat-icon">‚úÖ</div><div class="stat-value">0</div><div class="stat-label">Reproduced</div></div></div></div></div></section><section class="section-hero"><div class="container"><div class="text--center margin-bottom--lg"><h2 class="text-gradient">Browse Papers by Research Area</h2><p class="section-description">Select one or more research areas to filter papers. Papers must match ALL selected areas.</p></div><div class="filterTabs_BnEP"><button class="filterTab_dqoF filterTabActive_YS05" style="--filter-color:#718096">All Papers</button><button class="filterTab_dqoF" style="--filter-color:#4299e1">Attention Mechanisms</button><button class="filterTab_dqoF" style="--filter-color:#48bb78">Efficient Training</button><button class="filterTab_dqoF" style="--filter-color:#9f7aea">Interpretability</button><button class="filterTab_dqoF" style="--filter-color:#f56565">Multimodal</button><button class="filterTab_dqoF" style="--filter-color:#ed8936">RAG Systems</button><button class="filterTab_dqoF" style="--filter-color:#718096">Security</button></div><div class="controlsRow_Ba_w"><div class="sortDropdown_DGM4"><label for="external-sort-select" class="sortLabel_jqvb">Sort by:</label><select id="external-sort-select" class="sortSelect_TzSh"><option value="year-desc" selected="">Year (Newest First)</option><option value="year-asc">Year (Oldest First)</option><option value="title-asc">Title (A-Z)</option><option value="title-desc">Title (Z-A)</option></select></div></div><div class="papersGrid_uBqp"><div class="paperCard_ReeH"><div class="paperHeader_AQL8"><div class="paperMeta_DZyK"><span class="paperDate_eqa8">2025</span></div><div class="paperTags_e6B6"><span class="paperTag_iRZY" style="background-color:#ed8936">Reproduction: <!-- -->In Progress</span><span class="paperTag_iRZY" style="background-color:#ed8936">P2</span><span class="paperTag_iRZY" style="background-color:#9f7aea">Interpretability</span></div></div><div class="paperContent_je0v"><h3 class="paperTitle_WTB3">On the Biology of a Large Language Model</h3><div class="paperAuthors_ghYl">By Lindsey J et al</div><div class="paperVenue_W4TK">Published in: <strong>Transformer Circuits</strong></div><p class="paperAbstract_IQTE"><strong>Citation:</strong> <!-- -->Lindsey J et al. (2025). On the Biology of a Large Language Model. Transformer Circuits</p><p class="paperAbstract_IQTE"><strong>Notes:</strong> <!-- -->Mechanistic interpretability research</p></div><div class="paperActions_KBA_"><a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html" class="button button--primary button--sm" target="_blank" rel="noopener noreferrer">View Paper</a></div></div><div class="paperCard_ReeH"><div class="paperHeader_AQL8"><div class="paperMeta_DZyK"><span class="paperDate_eqa8">2025</span></div><div class="paperTags_e6B6"><span class="paperTag_iRZY" style="background-color:#4299e1">Reproduction: <!-- -->Triaged</span><span class="paperTag_iRZY" style="background-color:#ed8936">P2</span><span class="paperTag_iRZY" style="background-color:#9f7aea">Interpretability</span></div></div><div class="paperContent_je0v"><h3 class="paperTitle_WTB3">Tracing the thoughts of a large language model</h3><div class="paperAuthors_ghYl">By Anthropic Team</div><div class="paperVenue_W4TK">Published in: <strong>Anthropic</strong></div><p class="paperAbstract_IQTE"><strong>Citation:</strong> <!-- -->Anthropic Team. (2025). Tracing the thoughts of a large language model. Anthropic Research</p><p class="paperAbstract_IQTE"><strong>Notes:</strong> <!-- -->Monitor for opportunities</p></div><div class="paperActions_KBA_"><a href="https://www.anthropic.com/research/tracing-thoughts-language-model" class="button button--primary button--sm" target="_blank" rel="noopener noreferrer">View Paper</a></div></div><div class="paperCard_ReeH"><div class="paperHeader_AQL8"><div class="paperMeta_DZyK"><span class="paperDate_eqa8">2025</span></div><div class="paperTags_e6B6"><span class="paperTag_iRZY" style="background-color:#4299e1">Reproduction: <!-- -->Triaged</span><span class="paperTag_iRZY" style="background-color:#ed8936">P2</span><span class="paperTag_iRZY" style="background-color:#ed8936">RAG Systems</span></div></div><div class="paperContent_je0v"><h3 class="paperTitle_WTB3">Agentic RAG with uncertainty routing</h3><div class="paperAuthors_ghYl">By Lee S, Patel R</div><div class="paperVenue_W4TK">Published in: <strong>arXiv</strong></div><p class="paperAbstract_IQTE"><strong>Citation:</strong> <!-- -->Lee S &amp; Patel R. (2025). Agentic RAG with uncertainty routing. arXiv:2501.01234</p><p class="paperAbstract_IQTE"><strong>Notes:</strong> <!-- -->Wait for code release</p></div><div class="paperActions_KBA_"><a href="https://arxiv.org/abs/2501.01234" class="button button--primary button--sm" target="_blank" rel="noopener noreferrer">View Paper</a><a href="https://arxiv.org/pdf/2501.01234.pdf" class="button button--secondary button--sm" target="_blank" rel="noopener noreferrer">PDF</a></div></div><div class="paperCard_ReeH"><div class="paperHeader_AQL8"><div class="paperMeta_DZyK"><span class="paperDate_eqa8">2025</span></div><div class="paperTags_e6B6"><span class="paperTag_iRZY" style="background-color:#ed8936">Reproduction: <!-- -->In Progress</span><span class="paperTag_iRZY" style="background-color:#f56565">P0</span><span class="paperTag_iRZY" style="background-color:#4299e1">Attention Mechanisms</span><span class="paperTag_iRZY" style="background-color:#48bb78">Efficient Training</span></div></div><div class="paperContent_je0v"><h3 class="paperTitle_WTB3">XAttention: Block Sparse Attention with Antidiagonal Scoring</h3><div class="paperAuthors_ghYl">By Xu R, Xiao G, Huang H, Guo J, Han S</div><div class="paperVenue_W4TK">Published in: <strong>arXiv</strong></div><p class="paperAbstract_IQTE"><strong>Citation:</strong> <!-- -->Xu R et al. (2025). XAttention: Block Sparse Attention with Antidiagonal Scoring. arXiv:2503.16428</p><p class="paperAbstract_IQTE"><strong>Notes:</strong> <!-- -->High priority reproduction target</p></div><div class="paperActions_KBA_"><a href="https://arxiv.org/abs/2503.16428" class="button button--primary button--sm" target="_blank" rel="noopener noreferrer">View Paper</a><a href="https://arxiv.org/pdf/2503.16428.pdf" class="button button--secondary button--sm" target="_blank" rel="noopener noreferrer">PDF</a><a href="https://github.com/mit-han-lab/x-attention" class="button button--secondary button--sm" target="_blank" rel="noopener noreferrer">View Code</a></div></div><div class="paperCard_ReeH"><div class="paperHeader_AQL8"><div class="paperMeta_DZyK"><span class="paperDate_eqa8">2024</span></div><div class="paperTags_e6B6"><span class="paperTag_iRZY" style="background-color:#4299e1">Reproduction: <!-- -->Triaged</span><span class="paperTag_iRZY" style="background-color:#f56565">P0</span><span class="paperTag_iRZY" style="background-color:#718096">Security</span></div></div><div class="paperContent_je0v"><h3 class="paperTitle_WTB3">Effective Prompt Extraction from Language Models</h3><div class="paperAuthors_ghYl">By Yiming Zhang, Nicholas Carlini, Daphne Ippolito</div></div><div class="paperActions_KBA_"><a href="https://doi.org/10.48550/arXiv.2307.06865" class="button button--primary button--sm" target="_blank" rel="noopener noreferrer">View Paper</a><a href="https://arxiv.org/abs/2307.06865v3" class="button button--secondary button--sm" target="_blank" rel="noopener noreferrer">PDF</a><a href="https://github.com/y0mingzhang/prompt-extraction" class="button button--secondary button--sm" target="_blank" rel="noopener noreferrer">View Code</a></div></div><div class="paperCard_ReeH"><div class="paperHeader_AQL8"><div class="paperMeta_DZyK"><span class="paperDate_eqa8">2024</span></div><div class="paperTags_e6B6"><span class="paperTag_iRZY" style="background-color:#4299e1">Reproduction: <!-- -->Triaged</span><span class="paperTag_iRZY" style="background-color:#718096">P3</span><span class="paperTag_iRZY" style="background-color:#f56565">Multimodal</span></div></div><div class="paperContent_je0v"><h3 class="paperTitle_WTB3">Multimodal pretraining for medical imaging</h3><div class="paperAuthors_ghYl">By Zhang L et al</div><div class="paperVenue_W4TK">Published in: <strong>ICLR</strong></div><p class="paperAbstract_IQTE"><strong>Citation:</strong> <!-- -->Zhang L et al. (2024). Multimodal pretraining for medical imaging. ICLR 2024</p><p class="paperAbstract_IQTE"><strong>Notes:</strong> <!-- -->Out of scope - privacy concerns</p></div><div class="paperActions_KBA_"><a href="https://arxiv.org/abs/2312.22222" class="button button--primary button--sm" target="_blank" rel="noopener noreferrer">View Paper</a><a href="https://arxiv.org/pdf/2312.22222.pdf" class="button button--secondary button--sm" target="_blank" rel="noopener noreferrer">PDF</a></div></div><div class="paperCard_ReeH"><div class="paperHeader_AQL8"><div class="paperMeta_DZyK"><span class="paperDate_eqa8">2024</span></div><div class="paperTags_e6B6"><span class="paperTag_iRZY" style="background-color:#4299e1">Reproduction: <!-- -->Triaged</span><span class="paperTag_iRZY" style="background-color:#f56565">P0</span><span class="paperTag_iRZY" style="background-color:#48bb78">Efficient Training</span></div></div><div class="paperContent_je0v"><h3 class="paperTitle_WTB3">Scaling-efficient finetuning with sparse adapters</h3><div class="paperAuthors_ghYl">By Doe J, Smith A</div><div class="paperVenue_W4TK">Published in: <strong>NeurIPS</strong></div><p class="paperAbstract_IQTE"><strong>Citation:</strong> <!-- -->Doe J &amp; Smith A. (2024). Scaling-efficient finetuning with sparse adapters. NeurIPS 2024</p><p class="paperAbstract_IQTE"><strong>Notes:</strong> <!-- -->Cost reduction aligned</p></div><div class="paperActions_KBA_"><a href="https://arxiv.org/abs/2406.12345" class="button button--primary button--sm" target="_blank" rel="noopener noreferrer">View Paper</a><a href="https://arxiv.org/pdf/2406.12345.pdf" class="button button--secondary button--sm" target="_blank" rel="noopener noreferrer">PDF</a><a href="https://github.com/example/sparse-adapters" class="button button--secondary button--sm" target="_blank" rel="noopener noreferrer">View Code</a></div></div></div></div></section><section class="section-hero"><div class="container"><div class="row"><div class="col col--10 col--offset-1"><div class="cta-card"><h2 style="margin-bottom:1rem">Suggest Papers for Reproduction</h2><p style="margin-bottom:2rem;font-size:1.1rem">Found an interesting paper that should be reproduced? Help us validate and build upon existing research by suggesting papers for our reproduction pipeline.</p><div data-tf-live="01K3KYXX0T6VWNG0C3DJB44DWF" style="min-height:600px;width:100%"></div></div></div></div></div></section></main></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Research</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Research Engineering Path</a></li><li class="footer__item"><a class="footer__link-item" href="/internal-papers">Internal Papers</a></li><li class="footer__item"><a class="footer__link-item" href="/external-papers">External Papers</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/7gzZMAPuGr" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/averagejoeslab" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Content</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a class="footer__link-item" href="/#story">About Us</a></li><li class="footer__item"><a class="footer__link-item" href="/#mission">Mission</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2025 Average Joes Lab - All rights reserved.</div></div></div></footer></div>
</body>
</html>